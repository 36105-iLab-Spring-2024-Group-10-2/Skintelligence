{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b6006d-596d-4496-9d3c-e6c2430d412e",
   "metadata": {},
   "source": [
    "# Skintelligence\n",
    "## Dataset splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c158be36-2f0f-4751-a14c-12d9b262cabc",
   "metadata": {},
   "source": [
    "Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7764925-9bb5-4660-b6a2-0ba375b436e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ea6f79-9f2e-4e36-9c23-c85c9dd7ba97",
   "metadata": {},
   "source": [
    "Set the project and file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c354f6f-7802-4aec-87e9-73289513d10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = os.path.join(os.getcwd(), os.pardir)\n",
    "vqa_file = os.path.join(proj_dir, 'Data', 'Final', 'Final Complete Dataset.csv')\n",
    "train_img_file = os.path.join(proj_dir, 'Data', 'Final', 'img_train.csv')\n",
    "val_img_file = os.path.join(proj_dir, 'Data', 'Final', 'img_val.csv')\n",
    "test_img_file = os.path.join(proj_dir, 'Data', 'Final', 'img_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb41b395-19cc-4092-804a-a13cc4749d6b",
   "metadata": {},
   "source": [
    "Read the vqa csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b10c6f59-6bc9-46d9-84ab-4e5bb89d1f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(vqa_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ec1850-2727-4351-91f0-160cfb3a0ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'skincap_file_path', 'ori_file_path', 'caption_zh_polish_en',\n",
       "       'disease', 'question', 'answer', 'caption_zh', 'caption_zh_polish',\n",
       "       'remark', 'source', 'skin_tone', 'malignant', 'fitzpatrick_scale',\n",
       "       'fitzpatrick_centaur', 'nine_partition_label', 'three_partition_label',\n",
       "       'url', 'Vesicle', 'Papule', 'Macule', 'Plaque', 'Abscess', 'Pustule',\n",
       "       'Bulla', 'Patch', 'Nodule', 'Ulcer', 'Crust', 'Erosion', 'Excoriation',\n",
       "       'Atrophy', 'Exudate', 'Purpura/Petechiae', 'Fissure', 'Induration',\n",
       "       'Xerosis', 'Telangiectasia', 'Scale', 'Scar', 'Friable', 'Sclerosis',\n",
       "       'Pedunculated', 'Exophytic/Fungating', 'Warty/Papillomatous',\n",
       "       'Dome-shaped', 'Flat topped', 'Brown(Hyperpigmentation)', 'Translucent',\n",
       "       'White(Hypopigmentation)', 'Purple', 'Yellow', 'Black', 'Erythema',\n",
       "       'Comedo', 'Lichenification', 'Blue', 'Umbilicated', 'Poikiloderma',\n",
       "       'Salmon', 'Wheal', 'Acuminate', 'Burrow', 'Gray', 'Pigmented', 'Cyst',\n",
       "       'Do not consider this image'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ef222a-294c-4c4b-911b-5953c5c5fed1",
   "metadata": {},
   "source": [
    "Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d1417b-7719-4bd6-8c61-eddc4077f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace hyphen with space\n",
    "df['disease'] = df['disease'].str.replace('-', ' ')\n",
    "\n",
    "# Drop the unwanted columns\n",
    "df_images = df.drop(['id', 'ori_file_path', 'caption_zh_polish_en', 'question', 'answer', 'caption_zh', 'caption_zh_polish', 'remark', 'source', 'skin_tone', 'malignant', 'fitzpatrick_scale', 'fitzpatrick_centaur', 'nine_partition_label', 'three_partition_label', 'url', 'Do not consider this image'], axis=1)\n",
    "df_images = df_images.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b8fdf8-fc84-4557-9751-7c6ad5042899",
   "metadata": {},
   "source": [
    "Function to perform stratified data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b21a4b74-be41-4a7c-aeec-d9df3bd9f341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to split the data based on the disease column\n",
    "def stratified_split(df, disease_column, min_representation, train_size=0.6, val_size=0.2, test_size=0.2):\n",
    "    \n",
    "    # Assigning under-represented diseases to the training set\n",
    "    disease_counts = df[disease_column].value_counts()\n",
    "    small_disease_df = df[df[disease_column].isin(disease_counts[disease_counts <= min_representation].index)]\n",
    "    large_disease_df = df[~df[disease_column].isin(disease_counts[disease_counts <= min_representation].index)]\n",
    "    \n",
    "    # Split the remaining data for larger disease categories\n",
    "    train_data, temp_data = train_test_split(\n",
    "        large_disease_df, stratify=large_disease_df[disease_column], test_size=(val_size + test_size)\n",
    "    )\n",
    "    \n",
    "    # Split the temporary dataset into validation and test sets\n",
    "    val_data, test_data = train_test_split(\n",
    "        temp_data, stratify=temp_data[disease_column], test_size=test_size / (val_size + test_size)\n",
    "    )\n",
    "    \n",
    "    # Add the small disease entries to the training set\n",
    "    train_data = pd.concat([train_data, small_disease_df])\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39a621bc-30a1-4b8c-930b-aa70142ddb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a stratified split based on diseases\n",
    "df_img_train, df_img_val, df_img_test = stratified_split(df_images, 'disease', 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c1077b-4f46-4a8b-b1cd-60f173c65df6",
   "metadata": {},
   "source": [
    "Check the length of the training, validation and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53232bb3-637f-449b-be3c-42eece940109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 2426\n",
      "Validation set size: 785\n",
      "Test set size: 785\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set size:\", len(df_img_train))\n",
    "print(\"Validation set size:\", len(df_img_val))\n",
    "print(\"Test set size:\", len(df_img_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3761de-bbfe-43fb-a9da-8acf93bb147e",
   "metadata": {},
   "source": [
    "Save the split datasets into separate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bf45eaa-5210-433b-9fb7-a49ae9f231d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_train.to_csv(train_img_file, index=False)\n",
    "df_img_val.to_csv(val_img_file, index=False)\n",
    "df_img_test.to_csv(test_img_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
