{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aad9b7f9-3d48-45e3-8f4b-2a5e8cb367a6",
   "metadata": {},
   "source": [
    "# Skintelligence\n",
    "## Image feature extraction and Multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e8036b-6067-4fa8-b146-eed644154d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import multilabel_confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision import models, datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76d5c143-dbc6-4580-8175-4f7b7ade06cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = os.path.join(os.getcwd(), os.pardir)\n",
    "img_dir = os.path.join(proj_dir, 'Data', 'Raw', 'Images')\n",
    "vqa_filepath = os.path.join(proj_dir, 'Data', 'Processed', 'skincap_vqa.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e8bfb9-a79b-4373-8373-a432f412dedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(vqa_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f76ccc-7cc9-4c2a-b489-0ccde5e10233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['skincap_file_path', 'disease', 'caption_zh_polish_en', 'Vesicle',\n",
       "       'Papule', 'Macule', 'Plaque', 'Abscess', 'Pustule', 'Bulla', 'Patch',\n",
       "       'Nodule', 'Ulcer', 'Crust', 'Erosion', 'Excoriation', 'Atrophy',\n",
       "       'Exudate', 'Purpura/Petechiae', 'Fissure', 'Induration', 'Xerosis',\n",
       "       'Telangiectasia', 'Scale', 'Scar', 'Friable', 'Sclerosis',\n",
       "       'Pedunculated', 'Exophytic/Fungating', 'Warty/Papillomatous',\n",
       "       'Dome-shaped', 'Flat topped', 'Brown(Hyperpigmentation)', 'Translucent',\n",
       "       'White(Hypopigmentation)', 'Purple', 'Yellow', 'Black', 'Erythema',\n",
       "       'Comedo', 'Lichenification', 'Blue', 'Umbilicated', 'Poikiloderma',\n",
       "       'Salmon', 'Wheal', 'Acuminate', 'Burrow', 'Gray', 'Pigmented', 'Cyst',\n",
       "       'Do not consider this image', 'question', 'answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6657b5a-21f8-4cf6-bee5-27c0bcad6b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med_annot = df.drop(['caption_zh_polish_en', 'question', 'answer', 'Do not consider this image'], axis=1)\n",
    "df_med_annot['disease'] = df_med_annot['disease'].str.replace('-',' ')\n",
    "df_med_annot = df_med_annot.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57840cb9-3d70-4fab-b619-72fe8bb5c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sample = df_med_annot.groupby('disease').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f634ff9-4481-4840-8b98-3bd408800b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med_annot = df_med_annot.drop(['disease'], axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd669193-1935-4c00-9447-89f51a54f0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the columns that have less number of 1 values as we do not have enough representation of this label in the dataset\n",
    "threshold = 0\n",
    "med_annot_names = [column for column in df_med_annot.columns if column != 'skincap_file_path']\n",
    "column_sum = (df_med_annot[med_annot_names] == 1).sum()\n",
    "columns_to_keep = column_sum[column_sum > threshold].index\n",
    "med_annot_names = columns_to_keep\n",
    "columns_to_keep = ['skincap_file_path'] + list(med_annot_names)\n",
    "df_med_annot = df_med_annot[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d093bb9-4d78-4d2d-84eb-db8c3d637128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['skincap_file_path', 'Vesicle', 'Papule', 'Macule', 'Plaque', 'Abscess',\n",
       "       'Pustule', 'Bulla', 'Patch', 'Nodule', 'Ulcer', 'Crust', 'Erosion',\n",
       "       'Excoriation', 'Atrophy', 'Exudate', 'Purpura/Petechiae', 'Fissure',\n",
       "       'Induration', 'Xerosis', 'Telangiectasia', 'Scale', 'Scar', 'Friable',\n",
       "       'Sclerosis', 'Pedunculated', 'Exophytic/Fungating',\n",
       "       'Warty/Papillomatous', 'Dome-shaped', 'Flat topped',\n",
       "       'Brown(Hyperpigmentation)', 'Translucent', 'White(Hypopigmentation)',\n",
       "       'Purple', 'Yellow', 'Black', 'Erythema', 'Comedo', 'Lichenification',\n",
       "       'Blue', 'Umbilicated', 'Poikiloderma', 'Salmon', 'Wheal', 'Acuminate',\n",
       "       'Burrow', 'Gray', 'Pigmented', 'Cyst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_med_annot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ac007e4-8e0e-4e8a-b25d-86de529085d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(df_med_annot, test_size=0.375, random_state=42)\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b9f5b41-19b2-4d31-8218-3ad2210bce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_dir, data, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.data = data\n",
    "        self.img_ids = list(data.keys())\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.data.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File not found: {img_id}\")\n",
    "\n",
    "            image = torch.zeros(3, 224, 224)\n",
    "        \n",
    "        # Get the labels (binary annotations)\n",
    "        labels = self.data.iloc[idx, 1:].values.astype(int)\n",
    "        labels = torch.tensor(labels)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c01ebb04-c412-41e3-850d-623c87a729c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(40),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "338b761c-319e-4b48-99a0-c667293cbb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(img_dir = img_dir,\n",
    "                              data = df_train,\n",
    "                              transform = train_transform)\n",
    "\n",
    "val_dataset = CustomDataset(img_dir = img_dir,\n",
    "                              data = df_val,\n",
    "                              transform = test_transform)\n",
    "\n",
    "test_dataset = CustomDataset(img_dir = img_dir,\n",
    "                              data = df_test,\n",
    "                              transform = test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd6651b9-e35e-4c95-9262-610fffbc59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1342601-7cf7-4a87-8af9-8d59225f056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the training dataset is: 2500\n",
      "The size of the validation dataset is: 750\n",
      "The size of the testing dataset is: 750\n"
     ]
    }
   ],
   "source": [
    "print('The size of the training dataset is:', len(train_dataset))\n",
    "print('The size of the validation dataset is:', len(val_dataset))\n",
    "print('The size of the testing dataset is:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e02adfc1-ee74-436e-a184-69c7979b61eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16a9946d-2556-4237-905e-d25c7da68779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): Conv2dNormActivation(\n",
       "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=1280, bias=True)\n",
       "    (1): Hardswish()\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the pre-trained mobilenet_v3 model\n",
    "base_model_mobilenetv3 = models.mobilenet_v3_large(weights='IMAGENET1K_V1')\n",
    "\n",
    "base_model_mobilenetv3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f480eec-63c8-4b3b-b3ff-26233d46d2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all the layers\n",
    "for param in base_model_mobilenetv3.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "unfreeze_layers = [12, 13, 14, 15]  # Layer numbers to unfreeze\n",
    "for idx, (name, child) in enumerate(base_model_mobilenetv3.features.named_children()):  # Iterate through named children of the model\n",
    "    if idx in unfreeze_layers: # Check if the index is in the list of layers to be unfrozen\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = True  # Set requires_grad to True to unfreeze the parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccf102f8-28e9-4e0b-a731-01869f074472",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): Conv2dNormActivation(\n",
       "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=960, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=48, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ftrs_mobilenetv3 = base_model_mobilenetv3.classifier[0].in_features\n",
    "#base_model_mobilenetv3.classifier = nn.Sequential(\n",
    "#    nn.Linear(num_ftrs_mobilenetv3, 512),\n",
    "#    nn.ReLU(),\n",
    "#    nn.Linear(512, 256),\n",
    "#    nn.ReLU(),\n",
    "#    nn.Linear(256, len(df_med_annot.columns)-1),\n",
    "#    nn.Sigmoid()\n",
    "#)\n",
    "\n",
    "base_model_mobilenetv3.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs_mobilenetv3, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, len(df_med_annot.columns)-1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "model = base_model_mobilenetv3\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8cfbfa5-d2b8-426a-b99b-eb2413d68ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCELoss()  # For multi-label classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9ce42fc-8346-42fb-9149-8c8e4663a13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelManager:\n",
    "    \n",
    "    def __init__(self, early_stop_patience=5, reduce_lr_factor=0.2, reduce_lr_patience=3, reduce_lr_min_lr=0.0000001, checkpoint_path='mlc_mobilenet_checkpoint.pth', pred_prob_threshold=0.5):\n",
    "        # Initialize callback parameters\n",
    "        self.early_stop_patience = early_stop_patience  # Patience for early stopping\n",
    "        self.reduce_lr_factor = reduce_lr_factor  # Factor by which to reduce learning rate\n",
    "        self.reduce_lr_patience = reduce_lr_patience  # Patience for reducing learning rate\n",
    "        self.reduce_lr_min_lr = reduce_lr_min_lr  # Minimum learning rate\n",
    "        self.checkpoint_path = checkpoint_path  # Path to save model checkpoints\n",
    "        \n",
    "        # Initialize variables for early stopping\n",
    "        self.early_stop_counter = 0  # Counter for early stopping\n",
    "        self.best_val_loss = float('inf')  # Best validation loss\n",
    "\n",
    "        # Initialize prediction probability threshold\n",
    "        self.pred_prob_threshold = pred_prob_threshold\n",
    "\n",
    "        self.optimizer = None  # Optimizer for training\n",
    "        self.scheduler = None  # Learning rate scheduler\n",
    "    \n",
    "    def set_model(self, model):\n",
    "        self.model = model  # Set model\n",
    "        \n",
    "    def set_optimizer(self, optimizer):\n",
    "        # Set optimizer for training\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "    def on_epoch_end(self, epoch, val_loss):\n",
    "        # Early Stopping\n",
    "        if val_loss < self.best_val_loss:\n",
    "            self.best_val_loss = val_loss\n",
    "            self.early_stop_counter = 0  # Reset counter if validation loss improves\n",
    "\n",
    "             # Save the best model\n",
    "            torch.save(self.model.state_dict(), self.checkpoint_path)\n",
    "        else:\n",
    "            self.early_stop_counter += 1  # Increment counter if validation loss does not improve\n",
    "\n",
    "        if self.early_stop_counter >= self.early_stop_patience:\n",
    "            print(\"\\nEarly stopping triggered!\")\n",
    "            return True  # Stop training if early stopping criterion is met\n",
    "\n",
    "        # Reduce LR on Plateau\n",
    "        if self.scheduler is not None:\n",
    "            self.scheduler.step(val_loss)  # Adjust learning rate based on validation loss\n",
    "\n",
    "        return False  # Continue training\n",
    "\n",
    "    def on_train_begin(self):\n",
    "        # Initialize Reduce LR on Plateau scheduler\n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer, mode='min', factor=self.reduce_lr_factor,\n",
    "                                            patience=self.reduce_lr_patience, min_lr=self.reduce_lr_min_lr)\n",
    "    \n",
    "    def on_train_end(self):\n",
    "        # Load the best model parameters after training\n",
    "        self.model.load_state_dict(torch.load(self.checkpoint_path))\n",
    "        \n",
    "    def train_model(self, num_epochs, train_loader, val_loader):\n",
    "        # Initialize lists to store epoch-wise values\n",
    "        train_losses = []  # List to store training losses\n",
    "        val_losses = []  # List to store validation losses\n",
    "        train_true_labels = []  # List to store the true labels of the training dataset\n",
    "        train_pred_labels = []  # List to store the predicted labels of the training dataset\n",
    "        val_true_labels = []  # List to store the true labels of the validation dataset\n",
    "        val_pred_labels = []  # List to store the predicted labels of the validation dataset\n",
    "        #train_accuracies = []  # List to store training accuracies\n",
    "        #val_accuracies = []  # List to store validation accuracies\n",
    "\n",
    "        # Initiate training. Instantiate the scheduler\n",
    "        self.on_train_begin()\n",
    "        \n",
    "        current_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "        print('Training start time:', current_time)\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training\n",
    "            self.model.train()  # Set the model to training mode\n",
    "            current_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "            print(f'\\nEpoch: {epoch+1}, Training initiated at {current_time}')\n",
    "            running_train_loss = 0.0  # Initialize running training loss\n",
    "            \n",
    "            iteration = 0\n",
    "            for inputs, labels in train_loader:\n",
    "                iteration+=1\n",
    "                inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU if available\n",
    "                self.optimizer.zero_grad()  # Zero the parameter gradients\n",
    "                outputs = self.model(inputs)  # Forward pass\n",
    "                loss = criterion(outputs, labels.float())  # Calculate loss\n",
    "                \n",
    "                loss.backward()  # Backward pass\n",
    "                self.optimizer.step()  # Optimize parameters\n",
    "\n",
    "                running_train_loss += loss.item() * inputs.size(0)  # Accumulate training loss\n",
    "\n",
    "                train_true_labels += labels\n",
    "                train_pred_labels += (outputs > self.pred_prob_threshold).int()\n",
    "                #running_train_accuracy = accuracy_score(labels, predicted_labels) * inputs.size(0)  # Calculate accuracy score\n",
    "                \n",
    "                current_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "                print(f'Epoch: {epoch+1}, Training iteration: {iteration}/{len(train_loader)} completed at {current_time}', end='\\r')\n",
    "\n",
    "            # Calculate epoch-wise training loss and accuracy\n",
    "            epoch_train_loss = running_train_loss / len(train_loader.dataset)  # Average training loss\n",
    "            #epoch_train_accuracy = running_train_accuracy / len(train_loader.dataset)  # Average training accuracy\n",
    "            \n",
    "            # Validation\n",
    "            self.model.eval()  # Set the model to evaluation mode\n",
    "            current_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "            print(f'\\nEpoch: {epoch+1}, Validation initiated at {current_time}')\n",
    "            running_val_loss = 0.0  # Initialize running validation loss\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                iteration = 0\n",
    "                for inputs, labels in val_loader:\n",
    "                    iteration+=1\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU if available\n",
    "                    outputs = self.model(inputs)  # Forward pass\n",
    "                    \n",
    "                    loss = criterion(outputs, labels.float())  # Calculate loss\n",
    "\n",
    "                    running_val_loss += loss.item() * inputs.size(0)  # Accumulate validation loss\n",
    "                    \n",
    "                    val_true_labels += labels\n",
    "                    val_pred_labels += (outputs > self.pred_prob_threshold).int()\n",
    "                    #running_val_accuracy = accuracy_score(labels, predicted_labels) * inputs.size(0)  # Calculate accuracy score\n",
    "                \n",
    "                    current_time = time.strftime(\"%H:%M:%S\", time.localtime())\n",
    "                    print(f'Epoch: {epoch+1}, Validation iteration: {iteration}/{len(val_loader)} completed at {current_time}', end='\\r')\n",
    "            \n",
    "            # Calculate epoch-wise validation loss and accuracy\n",
    "            epoch_val_loss = running_val_loss / len(val_loader.dataset)  # Average validation loss\n",
    "            #epoch_val_accuracy = running_val_accuracy / len(val_loader.dataset)  # Average validation accuracy\n",
    "\n",
    "            print(f'\\nEpoch train loss: {round(epoch_train_loss, 5)}, Epoch val loss: {round(epoch_val_loss, 5)}')\n",
    "            #print(f'Epoch train accuracy: {round(epoch_train_accuracy, 5)}, Epoch val accuracy: {round(epoch_val_accuracy, 5)}')\n",
    "            \n",
    "            # Append values to lists\n",
    "            train_losses.append(epoch_train_loss)  # Append training loss\n",
    "            val_losses.append(epoch_val_loss)  # Append validation loss\n",
    "\n",
    "            #train_accuracies.append(epoch_train_accuracy)  # Append training loss\n",
    "            #val_accuracies.append(epoch_val_accuracy)  # Append validation loss\n",
    "            \n",
    "            # Check early stopping\n",
    "            if self.on_epoch_end(epoch, epoch_val_loss):\n",
    "                break  # Stop training if early stopping criterion is met\n",
    "\n",
    "        # End training. Load best parameters into the model\n",
    "        self.on_train_end()\n",
    "        \n",
    "        current_time = time.strftime(\"%H:%M:%S\", time.localtime())    \n",
    "        print('\\nTraining end time:', current_time)\n",
    "            \n",
    "        return model, train_losses, val_losses, train_true_labels, train_pred_labels, val_true_labels, val_pred_labels #, train_accuracies, val_accuracies\n",
    "    \n",
    "    def test_model(self, test_loader):\n",
    "\n",
    "        test_true_labels = []  # List to store the true labels of the testing dataset\n",
    "        test_pred_labels = []  # List to store the predicted labels of the testing dataset\n",
    "        \n",
    "        # Evaluation for test data\n",
    "        self.model.eval()  # Set model to evaluation mode\n",
    "        running_test_loss = 0.0  # Initialize running test loss\n",
    "\n",
    "        with torch.no_grad():  # Turn off gradients during evaluation\n",
    "            for inputs, labels in test_loader:  # Iterate through test data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)  # Move data to GPU\n",
    "                outputs = self.model(inputs)  # Get model predictions\n",
    "                loss = criterion(outputs, labels.float())  # Calculate loss\n",
    "\n",
    "                running_test_loss += loss.item() * inputs.size(0)  # Update running test loss\n",
    "\n",
    "                test_true_labels += labels\n",
    "                test_pred_labels += (outputs > self.pred_prob_threshold).int()\n",
    "                #running_test_accuracy = accuracy_score(labels, predicted_labels) * inputs.size(0)  # Calculate accuracy score\n",
    "                \n",
    "        # Calculate test loss and accuracy\n",
    "        test_loss = running_test_loss / len(test_loader.dataset)  # Average test loss\n",
    "        #test_accuracy = running_test_accuracy / len(test_loader.dataset)  # Average test accuracy \n",
    "        \n",
    "        return test_loss, test_true_labels, test_pred_labels #, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e9d6511-dbb3-44e9-bb77-a74bba5ae676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the ModelManager class\n",
    "model_manager = ModelManager()\n",
    "\n",
    "# Set the model in the model manager class\n",
    "model_manager.set_model(model)\n",
    "\n",
    "# Set the optimizer in the model manager class\n",
    "model_manager.set_optimizer(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e47f1-bb50-42a4-8726-d703a2023859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training start time: 15:21:35\n",
      "\n",
      "Epoch: 1, Training initiated at 15:21:35\n",
      "Epoch: 1, Training iteration: 50/50 completed at 15:29:46\n",
      "Epoch: 1, Validation initiated at 15:29:46\n",
      "Epoch: 1, Validation iteration: 15/15 completed at 15:30:54\n",
      "Epoch train loss: 0.25657, Epoch val loss: 2.35363\n",
      "\n",
      "Epoch: 2, Training initiated at 15:30:54\n",
      "Epoch: 2, Training iteration: 36/50 completed at 15:36:15\r"
     ]
    }
   ],
   "source": [
    "num_epochs = 20 # Number of epochs for training\n",
    "#model, train_losses, val_losses, train_accuracies, val_accuracies = model_manager.train_model(num_epochs, train_loader, val_loader)\n",
    "\n",
    "model, train_losses, val_losses, train_true_labels, train_pred_labels, val_true_labels, val_pred_labels = model_manager.train_model(num_epochs, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8bd77f-900d-45f1-b977-8fd232100888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(train_losses, validation_losses):\n",
    "    # Plot training and validation losses starting from index 1\n",
    "    epochs = range(1, len(train_losses) + 1)  # Generate the range of epochs starting from 1\n",
    "\n",
    "    # Plot training and validation losses\n",
    "    plt.plot(epochs, train_losses, label='Training Loss')  # Plot training losses over epochs\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss')  # Plot validation losses over epochs\n",
    "    plt.xlabel('Epoch')  # Set label for the x-axis\n",
    "    plt.ylabel('Loss')  # Set label for the y-axis\n",
    "    plt.title('Training and Validation Losses')  # Set title for the plot\n",
    "    plt.legend()  # Display legend\n",
    "    plt.grid(True)  # Display grid\n",
    "    plt.show()  # Show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705250fe-6ccf-4d8b-a12b-c5cee693a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plot(train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd0ba5-fce9-4f6e-89f5-ea04f87b3351",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_true_labels, test_pred_labels = model_manager.test_model(test_loader)\n",
    "print(f'The average test loss is {round(test_loss, 5)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d4df5f-8c46-4396-979d-3270da7f9d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(test_true_labels, test_pred_labels, target_names=med_annot_names, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f09f05-1ae5-4a62-8ca6-c197fd90eaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = multilabel_confusion_matrix(test_true_labels, test_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aa8b98-8930-40cd-aedd-392fd171abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(med_annot_names)):\n",
    "    fig, ax = plt.subplots(figsize=[3, 3])\n",
    "    ConfusionMatrixDisplay(confusion_matrix[i]).plot(ax=ax)\n",
    "    plt.title(med_annot_names[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1be4b9e-90ed-4cc9-9743-91870ce03f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "round(accuracy_score(train_true_labels, train_pred_labels, normalize=True, sample_weight=None), 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
