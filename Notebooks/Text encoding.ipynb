{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c56d2b1-876e-4692-b915-30b9121d6124",
   "metadata": {},
   "source": [
    "# Skintelligence\n",
    "## Custom model workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e823f5-99ea-46c9-be8a-f3f054acd0c5",
   "metadata": {},
   "source": [
    "### Importing packages and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec73f217-0cbe-441d-999e-074fc8384c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0ecff7b-757c-4c3e-be39-4204d9fc56c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = os.path.join(os.getcwd(), os.pardir)\n",
    "total_dataset_file = os.path.join(proj_dir, 'Data', 'Final', 'Final Complete Dataset.csv')\n",
    "train_img_file = os.path.join(proj_dir, 'Data', 'Final', 'img_train.csv')\n",
    "val_img_file = os.path.join(proj_dir, 'Data', 'Final', 'img_val.csv')\n",
    "test_img_file = os.path.join(proj_dir, 'Data', 'Final', 'img_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c321ead7-bfbe-49e6-a0df-f8f91913e638",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(total_dataset_file)\n",
    "df_img_train = pd.read_csv(train_img_file)\n",
    "df_img_val = pd.read_csv(val_img_file)\n",
    "df_img_test = pd.read_csv(test_img_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "871cd62f-cfa3-4369-976d-f59b5bfc0661",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id', 'ori_file_path', 'caption_zh_polish_en', 'caption_zh', 'caption_zh_polish', 'remark', 'source', 'skin_tone', 'malignant', 'fitzpatrick_scale', 'fitzpatrick_centaur', 'nine_partition_label', 'three_partition_label', 'url', 'Do not consider this image'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86b27f07-2ad6-4a77-ae4c-088f8ebf75f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['skincap_file_path', 'disease', 'question', 'answer', 'Vesicle',\n",
       "       'Papule', 'Macule', 'Plaque', 'Abscess', 'Pustule', 'Bulla', 'Patch',\n",
       "       'Nodule', 'Ulcer', 'Crust', 'Erosion', 'Excoriation', 'Atrophy',\n",
       "       'Exudate', 'Purpura/Petechiae', 'Fissure', 'Induration', 'Xerosis',\n",
       "       'Telangiectasia', 'Scale', 'Scar', 'Friable', 'Sclerosis',\n",
       "       'Pedunculated', 'Exophytic/Fungating', 'Warty/Papillomatous',\n",
       "       'Dome-shaped', 'Flat topped', 'Brown(Hyperpigmentation)', 'Translucent',\n",
       "       'White(Hypopigmentation)', 'Purple', 'Yellow', 'Black', 'Erythema',\n",
       "       'Comedo', 'Lichenification', 'Blue', 'Umbilicated', 'Poikiloderma',\n",
       "       'Salmon', 'Wheal', 'Acuminate', 'Burrow', 'Gray', 'Pigmented', 'Cyst'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1196fd94-e21a-4c2e-a653-dd312090d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column storing image name\n",
    "img_name_col = 'skincap_file_path'\n",
    "\n",
    "# Separating the medical annotation column names from the others\n",
    "med_annot_names = [column for column in df_img_train.columns if column not in [img_name_col, 'disease']]\n",
    "\n",
    "# Removing the columns that have less number of 1 values as we do not have enough representation of this label in the dataset\n",
    "threshold = 450\n",
    "\n",
    "column_sum = df_img_train[med_annot_names].sum()\n",
    "med_annot_names = column_sum[column_sum > threshold].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27c9c202-dc9b-4e54-a993-346a78f6cad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vqa_train = df[df[img_name_col].isin(df_img_train[img_name_col])]\n",
    "df_vqa_val = df[df[img_name_col].isin(df_img_val[img_name_col])]\n",
    "df_vqa_test = df[df[img_name_col].isin(df_img_test[img_name_col])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92f17aa9-c33e-49b2-94cd-a97413e50b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize questions and answers for the entire dataset\n",
    "questions = [item for item in df['question']]\n",
    "answers = [item for item in df['answer']]\n",
    "\n",
    "question_encoding = tokenizer(questions, padding=True, truncation=True, return_tensors='pt')\n",
    "answer_encoding = tokenizer(answers, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "df['question_input_ids'] = question_encoding['input_ids'].tolist()\n",
    "df['question_attention_mask'] = question_encoding['attention_mask'].tolist()\n",
    "\n",
    "df['answer_input_ids'] = answer_encoding['input_ids'].tolist()\n",
    "df['answer_attention_mask'] = answer_encoding['attention_mask'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3c74dd-d89a-41b3-8c0d-e1549536f855",
   "metadata": {},
   "source": [
    "### Multilabel classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85b4a9f7-904a-4ed2-bec1-d981077ba6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MLC model and load the pretrained weights\n",
    "mlc_model = models.mobilenet_v3_large(weights=None)\n",
    "num_ftrs_in = mlc_model.classifier[0].in_features\n",
    "mlc_model.classifier = nn.Sequential(\n",
    "    nn.Linear(num_ftrs_in, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(1024, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(512, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=0.2),\n",
    "    nn.Linear(256, len(med_annot_names)),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "mlc_model.load_state_dict(torch.load('mlc_mobilenet_checkpoint.pth'))\n",
    "mlc_model.eval()  # Set to evaluation mode since we are only extracting features\n",
    "\n",
    "# Freeze the MLC parameters so they are not updated during VQA training\n",
    "for param in mlc_model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf16d30-c0d5-461e-8528-9d6541de1fc9",
   "metadata": {},
   "source": [
    "### Image Feature Extractor / CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cd9d364-efdc-439e-8e46-4286644158e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = copy.deepcopy(mlc_model)\n",
    "cnn_model.classifier = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0c05018-c438-46d1-ac48-232877b1b99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "          (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "          (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "          (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "          (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "          (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (block): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (2): SqueezeExcitation(\n",
       "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (activation): ReLU()\n",
       "          (scale_activation): Hardsigmoid()\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (16): Conv2dNormActivation(\n",
       "      (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): Hardswish()\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad45648-d107-4e27-9502-f764625c9d8c",
   "metadata": {},
   "source": [
    "### Question-Answer Encoding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06519eaf-398f-4746-880f-f24c6d03e68c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the pretrained BERT model\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set BERT to evaluation mode to generate embeddings without training\n",
    "bert_model.eval()\n",
    "\n",
    "# Disable gradient calculations for efficiency\n",
    "#with torch.no_grad():\n",
    "    # Forward pass to get BERT embeddings for the questions\n",
    "    #question_outputs = bert_model(input_ids=question_input_ids, attention_mask=question_attention_mask)\n",
    "\n",
    "# Extract the [CLS] token embedding\n",
    "#question_embeddings = question_outputs.last_hidden_state[:, 0, :] #.tolist()  # Shape: (batch_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a23fa47-5653-4e6f-a954-5b8ba60de68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VQA Model without Attention\n",
    "class VQAModel(nn.Module):\n",
    "    def __init__(self, mlc_model, cnn_model, bert_model, hidden_size, vocab_size):\n",
    "        super(VQAModel, self).__init__()\n",
    "        self.mlc_model = mlc_model\n",
    "        self.cnn_model = cnn_model\n",
    "        self.bert_model = bert_model\n",
    "        self.lstm = nn.LSTM(input_size=1280 + 768 + len(med_annot_names), hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, images, questions, medical_annotations):\n",
    "        # Extract features from images using CNN\n",
    "        image_features = self.cnn_model(images)  # (batch_size, feature_size)\n",
    "\n",
    "        # Tokenize and embed the question using BERT\n",
    "        input_ids = questions['input_ids']\n",
    "        attention_mask = questions['attention_mask']\n",
    "\n",
    "        question_embeddings = self.bert_model(input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        question_embedding = question_embeddings.mean(dim=1)  # Mean across sequence length\n",
    "\n",
    "        # Concatenate image features, question embedding, and medical annotations\n",
    "        combined_features = torch.cat((image_features, question_embedding, medical_annotations), dim=1)\n",
    "\n",
    "        # Pass combined features through LSTM\n",
    "        lstm_out, (h_n, c_n) = self.lstm(combined_features.unsqueeze(1))  # (batch_size, seq_len=1, hidden_size)\n",
    "\n",
    "        # Final output layer to predict the answer as a sequence of words\n",
    "        output = self.fc(lstm_out[:, -1, :])  # Use the last output from LSTM\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38bc12e0-ab04-4078-b120-d21d62b90fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 512  # Adjust based on your needs\n",
    "vocab_size = len(tokenizer.vocab)  # Size of your vocabulary for sentence generation\n",
    "vqa_model = VQAModel(mlc_model, cnn_model, bert_model, hidden_size, vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ec85c6-6325-4ac2-9fe9-4e0a4f2f36a8",
   "metadata": {},
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, cnn_output_size, bert_hidden_size, annotation_size, attention_size):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        \n",
    "        # Linear layers to compute attention scores\n",
    "        self.image_fc = nn.Linear(cnn_output_size, attention_size)  # Image feature transformation\n",
    "        self.question_fc = nn.Linear(bert_hidden_size, attention_size)  # Question embedding transformation\n",
    "        self.annotation_fc = nn.Linear(annotation_size, attention_size)  # Annotation transformation\n",
    "        \n",
    "        # Output layer to get attention weights\n",
    "        self.attention_weight = nn.Linear(attention_size, 1)\n",
    "\n",
    "    def forward(self, image_features, question_embeddings, annotations):\n",
    "        \"\"\"\n",
    "        image_features: CNN output (batch_size, cnn_output_size)\n",
    "        question_embeddings: BERT question embeddings (batch_size, bert_hidden_size)\n",
    "        annotations: Multilabel annotation predictions (batch_size, annotation_size)\n",
    "        \"\"\"\n",
    "        \n",
    "        # Transform inputs into attention space\n",
    "        image_att = self.image_fc(image_features)  # Shape: (batch_size, attention_size)\n",
    "        question_att = self.question_fc(question_embeddings)  # Shape: (batch_size, attention_size)\n",
    "        annotation_att = self.annotation_fc(annotations)  # Shape: (batch_size, attention_size)\n",
    "        \n",
    "        # Combine the transformed features (sum of contributions from image, question, and annotations)\n",
    "        combined_att = image_att + question_att + annotation_att\n",
    "        \n",
    "        # Apply non-linearity (ReLU) and compute attention scores\n",
    "        attention_scores = F.relu(combined_att)\n",
    "        \n",
    "        # Compute attention weights (normalized across all inputs)\n",
    "        attention_weights = torch.sigmoid(self.attention_weight(attention_scores))  # Shape: (batch_size, 1)\n",
    "        \n",
    "        # Combine the inputs based on the attention weights\n",
    "        combined_features = (attention_weights * image_features) + (attention_weights * question_embeddings) + (attention_weights * annotations)\n",
    "        \n",
    "        return combined_features  # Shape: (batch_size, cnn_output_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
